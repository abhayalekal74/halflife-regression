# -*- coding: utf-8 -*-
"""topic-hlr-train.ipynb

Automatically generated by Colaboratory.

Original file is located at
	https://colab.research.google.com/drive/1P6QsFOhU8pusyMXomLsjCkfyQW7exD5H
"""

import pandas as pd
from datetime import datetime as dt
import math
import random
from collections import defaultdict, namedtuple
import sys
from tqdm import tqdm
import json
import argparse

MIN_REC = 0.0001
MAX_REC = 0.9999
MIN_HL = 1 #1 minute
MAX_HL = 30 #30 minutes
LN2 = math.log(2.)

Instance = namedtuple('Instance', ['recall', 'hl', 'time_delta', 'feature_vector'])


def to_minutes(millis):
	return (millis / 1000.0) / 60.0


def recall_clip(recall):
	return min(max(MIN_REC, recall), MAX_REC)


def halflife_clip(halflife):
	return min(max(MIN_HL, halflife), MAX_HL)


def mae(l1, l2):
	# mean average error
	return mean([abs(l1[i] - l2[i]) for i in range(len(l1))])


def mean(lst):
	# the average of a list
	return float(sum(lst)) / len(lst)


def spearmanr(l1, l2):
	# spearman rank correlation
	m1 = mean(l1)
	m2 = mean(l2)
	num = 0.
	d1 = 0.
	d2 = 0.
	for i in range(len(l1)):
		num += (l1[i]-m1) * (l2[i]-m2)
		d1 += (l1[i]-m1) ** 2
		d2 += (l2[i]-m2) ** 2
	try:
		return num/math.sqrt(d1 * d2)
	except ZeroDivisionError:
		return -1


def read_data(df):
	print ("Reading data...")
	data = list()
	for groupid, groupdf in df.groupby(['userid', 'examid', 'categoryid']):
		prev_session_end = None
		userid = groupid[0]
		examid = groupid[1]
		categoryid = groupid[2]
		for sessionid, session_group in groupdf.groupby(['date']):
			session_name = "{}".format(sessionid)
			total_attempts = len(session_group)
			correct_df = session_group[session_group['iscorrect'] == True]
			correct_attempts = len(correct_df)
			actual_recall = recall_clip(float(correct_df['difficulty'].sum()) / session_group['difficulty'].sum())
			session_begin_time = session_group['attempttime'].min()
			lag_time = 0 if not prev_session_end else to_minutes(session_begin_time - prev_session_end)
			actual_halflife = MIN_HL if lag_time == 0 else halflife_clip(-lag_time / math.log(actual_recall, 2))
			prev_session_end = session_group['attempttime'].max()
			data.append([userid, examid, categoryid, session_name, prev_session_end, actual_recall, lag_time, actual_halflife, total_attempts, correct_attempts])
	return data


def get_instances_from_data(data):
	instances = list()
	for datum in data:
		recall = datum[5]
		hl = datum[7]
		time_delta = datum[6]
		feature_vector = list()
		feature_vector.append((sys.intern('right'), math.sqrt(1 + datum[-1])))
		feature_vector.append((sys.intern('wrong'), math.sqrt(1 + datum[-2] - datum[-1])))
		feature_vector.append((sys.intern(datum[1]), 1.))
		feature_vector.append((sys.intern(str(datum[2])), 1.))
		instances.append(Instance(recall, hl, time_delta, feature_vector))
	splitpoint = int(0.9 * len(instances))
	trainset = instances[:splitpoint]
	rest = instances[splitpoint:]
	rest_split = int(0.7 * len(rest))
	testset = rest[:rest_split]
	validationset = rest[rest_split:]
	return trainset, testset, validationset 


class HLRModel(object):
	def __init__(self, initial_weights=None, lrate=.001, hlwt=.01, l2wt=.1, sigma=1.):
		self.weights = defaultdict(float)
		self.best_weights = defaultdict(float)
		if initial_weights is not None:
			self.weights.update(initial_weights)
			self.best_weights.update(initial_weights)
		self.fcounts = defaultdict(int)
		self.lrate = lrate
		self.hlwt = hlwt
		self.l2wt = l2wt
		self.sigma = sigma
		self.min_val_loss = float("inf") 


	def halflife(self, inst, base):
		# h = 2 ** (theta . x)
		try:
			theta_x_dot_product = sum([self.best_weights[feature]*value for (feature, value) in inst.feature_vector])
			return halflife_clip(base ** theta_x_dot_product) 
		except:
			return MAX_HL


	def predict(self, inst, base=2.):
		halflife = self.halflife(inst, base)
		recall = 2. ** (-inst.time_delta / halflife)
		return recall_clip(recall), halflife


	def get_validation_loss(self, validationset):
		validation_loss = 0.0
		for inst in validationset:
			slr, slh, recall, hl = self.losses(inst)
			validation_loss += slr + slh
		return validation_loss


	def train_update(self, inst, validationset):
		base = 2.
		recall, hl = self.predict(inst, base)
		dl_recall_dw = 2. * (recall - inst.recall) * (LN2 ** 2) * recall * (inst.time_delta / hl)
		dl_hl_dw = 2. * (hl - inst.hl) * LN2 * hl
		for (feature, value) in inst.feature_vector:
			rate = (1. / (1 + inst.recall)) * self.lrate / math.sqrt(1 + self.fcounts[feature])
			self.weights[feature] -= rate * dl_recall_dw * value
			self.weights[feature] -= rate * self.hlwt * dl_hl_dw * value
			# L2 regularization update
			self.weights[feature] -= rate * self.l2wt * self.weights[feature] / self.sigma ** 2
			# increment feature count for learning rate
			self.fcounts[feature] += 1
		val_loss = self.get_validation_loss(validationset)			
		if val_loss < self.min_val_loss:
			self.min_val_loss = val_loss
			self.best_weights = self.weights

	
	def train(self, trainset, validationset, save_weights_dest, epochs=5):
		for i in tqdm(range(epochs), desc="Epoch "):
			for inst in tqdm(trainset, desc="Training Instance "):
				self.train_update(inst, validationset)
			with open(save_weights_dest, 'w') as f:
				print("\n\nEpoch {}: val_loss {}\n".format(i, self.min_val_loss))
				f.write(json.dumps(self.best_weights))

	
	def losses(self, inst):
		recall, hl = self.predict(inst)
		stop_loss_recall = (inst.recall - recall) ** 2
		stop_loss_hl = (inst.hl - hl) ** 2
		return stop_loss_recall, stop_loss_hl, recall, hl


	def eval(self, testset):
		print ("Predicting...")
		results = {'recall': [], 'hl': [], 'pred_recall': [], 'pred_hl': [], 'sl_recall': [], 'sl_hl': []}
		for inst in testset:
			sl_recall, sl_hl, recall, hl = self.losses(inst)
			results['recall'].append(inst.recall)	 # ground truth
			results['hl'].append(inst.hl)
			results['pred_recall'].append(recall)		 # predictions
			results['pred_hl'].append(hl)
			results['sl_recall'].append(sl_recall)	  # loss function values
			results['sl_hl'].append(sl_hl)
			#print ("actual_rec {}, pred_rec {}, actual_hl {}, pred_hl {}, sl_rec {}, sl_hl {}".format(inst.recall, recall, inst.hl, hl, sl_recall, sl_hl))
		mae_recall = mae(results['recall'], results['pred_recall'])
		mae_hl = mae(results['hl'], results['pred_hl'])
		cor_recall = spearmanr(results['recall'], results['pred_recall'])
		cor_hl = spearmanr(results['hl'], results['pred_hl'])
		total_sl_recall = sum(results['sl_recall'])
		total_sl_hl = sum(results['sl_hl'])
		total_l2 = sum([x ** 2 for x in self.weights.values()])
		total_loss = total_sl_recall + self.hlwt * total_sl_hl + self.l2wt * total_l2
		print('total_loss=%.1f (recall=%.1f, hl=%.1f, l2=%.1f)\tmae(recall)=%.3f\tcor(recall)=%.3f\tmae(hl)=%.3f\tcor(hl)=%.3f\n' % (total_loss, total_sl_recall, self.hlwt * total_sl_hl, self.l2wt * total_l2, mae_recall, cor_recall, mae_hl, cor_hl))


def parse_args():
	parser = argparse.ArgumentParser()
	parser.add_argument('--weights', dest='weights', help="JSON file containing trained weights")
	parser.add_argument('--save-weights', dest='save_weights', default="saved_weights.csv", help='File to save the weights in')
	parser.add_argument('--epochs', dest='epochs', type=int, default=1, help='Epochs to train')
	parser.add_argument('--train-further', dest='train_further', default=False, action="store_true", help='If the weights should be trained further')
	parser.add_argument('attempts_file', help='CSV file containing attempts data')
	args = parser.parse_args()
	if not args.attempts_file:
		sys.exit('Please pass the attempts file')
	return args


if __name__=='__main__':
	args = parse_args()
	df = pd.read_csv(args.attempts_file)
	df['date'] = df.apply(lambda row: dt.fromtimestamp(row['attempttime']/1000).date(), axis=1) 
	df['hour'] = df.apply(lambda row: dt.fromtimestamp(row['attempttime']/1000).hour, axis=1)
	df = df.sort_values(by=['attempttime'], ascending=True)

	data = read_data(df)
	trainset, testset, validationset = get_instances_from_data(data)
	
	if args.weights:
		saved_weights = json.load(args.weights)
		model = HLRModel(initial_weights=saved_weights)
	else:
		saved_weights = None
		model = HLRModel()

	
	if not saved_weights or (saved_weights is not None and args.train_further):
		model.train(trainset, validationset, args.save_weights, epochs=args.epochs)

	model.eval(testset)
