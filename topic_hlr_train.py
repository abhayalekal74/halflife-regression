# -*- coding: utf-8 -*-
"""topic-hlr-train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P6QsFOhU8pusyMXomLsjCkfyQW7exD5H
"""

import pandas as pd
from datetime import datetime as dt
import math
import random
from collections import defaultdict, namedtuple
import sys

MIN_REC = 0.0001
MAX_REC = 0.9999
MIN_HL = 1 #1 minute
MAX_HL = 30 #30 minutes
LN2 = math.log(2.)

Instance = namedtuple('Instance', ['recall', 'hl', 'time_delta', 'feature_vector'])


def to_minutes(millis):
    return (millis / 1000.0) / 60.0


def recall_clip(recall):
    return min(max(MIN_REC, recall), MAX_REC)


def halflife_clip(halflife):
    return min(max(MIN_HL, halflife), MAX_HL)


def read_data(df):
	data = list()
	for groupid, groupdf in df.groupby(['userid', 'examid']):
		prev_session_end = None
		userid = groupid[0]
		examid = groupid[1]
		for sessionid, session_group in groupdf.groupby(['hour', 'minute']):
			session_name = "{}-{}".format(sessionid[0], sessionid[1])
			total_attempts = len(session_group)
			correct_df = session_group[session_group['iscorrect'] == True]
			correct_attempts = len(correct_df)
			actual_recall = recall_clip(float(correct_df['difficulty'].sum()) / session_group['difficulty'].sum())
			session_begin_time = session_group['attempttime'].min()
			lag_time = 0 if not prev_session_end else to_minutes(session_begin_time - prev_session_end)
			actual_halflife = MIN_HL if lag_time == 0 else halflife_clip(-lag_time / math.log(actual_recall, 2))
			prev_session_end = session_group['attempttime'].max()
			data.append([userid, examid, session_name, prev_session_end, actual_recall, lag_time, actual_halflife, total_attempts, correct_attempts])
	return data


def get_instances_from_data(data):
	instances = list()
	for datum in data:
		recall = datum[4]
		hl = datum[6]
		time_delta = datum[5]
		feature_vector = list()
		feature_vector.append((sys.intern('right'), math.sqrt(1 + datum[-1])))
		feature_vector.append((sys.intern('wrong'), math.sqrt(1 + datum[-2] - datum[-1])))
		instances.append(Instance(recall, hl, time_delta, feature_vector))
	splitpoint = int(0.9 * len(instances))
	return instances[:splitpoint], instances[splitpoint:]


class HLRModel(object):
    def __init__(self, initial_weights=None, lrate=.001, hlwt=.01, l2wt=.1, sigma=1.):
        self.weights = defaultdict(float)
        if initial_weights is not None:
            self.weights.update(initial_weights)
        self.fcounts = defaultdict(int)
        self.lrate = lrate
        self.hlwt = hlwt
        self.l2wt = l2wt
        self.sigma = sigma


    def halflife(self, inst, base):
        # h = 2 ** (theta . x)
        try:
            theta_x_dot_product = sum([self.weights[feature]*value for (feature, value) in inst.feature_vector])
            return halflife_clip(base ** theta_x_dot_product) 
        except:
            return MAX_HL


    def predict(self, inst, base=2.):
        halflife = self.halflife(inst, base)
        recall = 2. ** (-inst.time_delta / halflife)
        return recall_clip(recall), halflife


    def train_update(self, inst):
        base = 2.
        recall, hl = self.predict(inst, base)
        dl_recall_dw = 2. * (recall - inst.recall) * (LN2 ** 2) * recall * (inst.time_delta / hl)
        dl_hl_dw = 2. * (hl - inst.hl) * LN2 * hl
        for (feature, value) in inst.feature_vector:
            rate = (1. / (1 + inst.recall)) * self.lrate / math.sqrt(1 + self.fcounts[feature])
            self.weights[feature] -= rate * dl_recall_dw * value
            self.weights[feature] -= rate * self.hlwt * dl_hl_dw * value
            # L2 regularization update
            self.weights[feature] -= rate * self.l2wt * self.weights[feature] / self.sigma ** 2
            # increment feature count for learning rate
            self.fcounts[feature] += 1
            
    
    def train(self, trainset):
        for inst in trainset:
            self.train_update(inst)

    
    def losses(self, inst):
        recall, hl = self.predict(inst)
        stop_loss_recall = (inst.recall - recall) ** 2
        stop_loss_hl = (inst.hl - hl) ** 2
        return stop_loss_recall, stop_loss_hl, recall, hl


    def eval(self, testset):
        for inst in testset:
            sl_recall, sl_hl, recall, hl = self.losses(inst)
            print ("actual_rec {}, pred_rec {}, actual_hl {}, pred_hl {}, sl_rec {}, sl_hl {}".format(inst.recall, recall, inst.hl, hl, sl_recall, sl_hl))


if __name__=='__main__':
	df = pd.read_csv(sys.argv[1])
	df['hour'] = df.apply(lambda row: dt.fromtimestamp(row['attempttime']/1000).hour, axis=1) 
	df['minute'] = df.apply(lambda row: dt.fromtimestamp(row['attempttime']/1000).minute, axis=1)
	df = df.sort_values(by=['attempttime'], ascending=True)

	data = read_data(df)
	trainset, testset = get_instances_from_data(data)
	
	model = HLRModel()
	model.train(trainset)
	model.eval(testset)

